{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTqxhuN8cPREHVO71tEktC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So9eFOLFEP4c",
        "outputId": "de75c683-ae6c-42f1-c6ef-84d276b9d16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CpMUNk_EX1i",
        "outputId": "022e5569-ba81-4791-f74d-f8df3c4f7d9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "id": "tV22sB9gEYzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd022b4-b4a6-4e22-d51e-3ce32f3704b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfv4bZCEaEf",
        "outputId": "f5b512b9-c937-4c0a-d60e-fded5be59cd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('stand/stand.csv')\n",
        "PRC = pd.read_csv('stand/stand_par.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "lSeKq_G5EbHF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y3d0mefjEjUT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "FMdzcvvXEmLp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del score[0]\n",
        "del score[1]\n",
        "del score[2]\n",
        "del score[3]\n",
        "del score[7]\n",
        "del score[9]\n",
        "del score[10]\n",
        "del score[13]\n",
        "del score[15]\n",
        "del score[16]\n",
        "del score[17]\n",
        "del score[18]\n",
        "del score[19]\n",
        "del score[20]\n",
        "del score[21]\n",
        "del score[22]\n",
        "del score[23]\n",
        "del score[24]\n",
        "del score[25]\n",
        "del score[26]\n",
        "del score[27]\n",
        "del score[31]\n",
        "del score[34]\n",
        "del score[36]\n",
        "del score[39]\n",
        "del score[44]\n",
        "del score[45]"
      ],
      "metadata": {
        "id": "BgyCQsxyEoVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK73bpUsEqMc",
        "outputId": "a461e8d7-2608-4f1b-e8f3-5fb70237b1ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## BBS High\n",
        "print('BBS High:', y.count(1))\n",
        "## BBS Low\n",
        "print('BBS Low:', y.count(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqMU4YFcXtsm",
        "outputId": "e38dcf63-ee15-42e0-92d2-1edbdbe941db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BBS High: 14\n",
            "BBS Low: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-paretic Side"
      ],
      "metadata": {
        "id": "R6saQXBUEtzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)\n",
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1NwUrLXErpM",
        "outputId": "73f5cd7b-b591-4194-c8a4-f48001311af2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상수항 없이 내용\n",
        "X = non.loc[:,['PC2','PC10','PC15']]\n",
        "y = non['score']\n",
        "import statsmodels.api as sm\n",
        "reg = sm.Logit(y,X).fit()\n",
        "print(reg.summary())\n",
        "print(np.exp(reg.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fj1289Mqfzt",
        "outputId": "3d0ed372-ea7e-4f43-ba8a-8a187f9e5ffb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.364835\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   No. Observations:                   19\n",
            "Model:                          Logit   Df Residuals:                       16\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Wed, 24 Jan 2024   Pseudo R-squ.:                  0.3670\n",
            "Time:                        07:46:20   Log-Likelihood:                -6.9319\n",
            "converged:                       True   LL-Null:                       -10.950\n",
            "Covariance Type:            nonrobust   LLR p-value:                   0.01798\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "PC2           -0.1104      0.055     -2.005      0.045      -0.218      -0.002\n",
            "PC10           0.1589      0.090      1.757      0.079      -0.018       0.336\n",
            "PC15          -0.2979      0.196     -1.518      0.129      -0.682       0.087\n",
            "==============================================================================\n",
            "PC2     0.895511\n",
            "PC10    1.172265\n",
            "PC15    0.742382\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상수항 추가한 내용(오류)\n",
        "X = non.loc[:,['PC2','PC10','PC15']]\n",
        "y = non['score']\n",
        "X = sm.add_constant(X,has_constant=\"add\")\n",
        "logit = sm.Logit(y, X)\n",
        "result = logit.fit()\n",
        "print(result.summary2())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6uuBAiRw9al",
        "outputId": "5867e33d-0631-4cdf-e2c4-0c4080ed8491"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Maximum number of iterations has been exceeded.\n",
            "         Current function value: 0.000000\n",
            "         Iterations: 35\n",
            "                          Results: Logit\n",
            "==================================================================\n",
            "Model:              Logit            Method:           MLE        \n",
            "Dependent Variable: score            Pseudo R-squared: 1.000      \n",
            "Date:               2024-01-24 07:55 AIC:              8.0000     \n",
            "No. Observations:   19               BIC:              11.7778    \n",
            "Df Model:           3                Log-Likelihood:   -1.3899e-09\n",
            "Df Residuals:       15               LL-Null:          -10.950    \n",
            "Converged:          0.0000           LLR p-value:      6.8409e-05 \n",
            "No. Iterations:     35.0000          Scale:            1.0000     \n",
            "------------------------------------------------------------------\n",
            "       Coef.     Std.Err.     z    P>|z|     [0.025       0.975]  \n",
            "------------------------------------------------------------------\n",
            "const  90.4611 111877.3123  0.0008 0.9994 -219185.0418 219365.9639\n",
            "PC2    -4.8530   6592.5047 -0.0007 0.9994  -12925.9249  12916.2189\n",
            "PC10   10.2718  13171.9193  0.0008 0.9994  -25806.2157  25826.7592\n",
            "PC15  -19.4724  25252.9172 -0.0008 0.9994  -49514.2807  49475.3358\n",
            "==================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
            "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC2','PC10','PC15']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "LkGOvGZTEvfm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "z13gQSGCE0mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "print(\"f1-score:\", f1_lr)\n",
        "\n",
        "# auc 계산\n",
        "auc_lr = roc_auc_score(y_test,y_pred_lr)\n",
        "print(\"AUC:\",auc_lr)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El6jdv5QExYm",
        "outputId": "08c1b5e6-69bb-49ff-ed3d-f5720d72cc7b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy: 0.875\n",
            "f1-score: 0.923076923076923\n",
            "AUC: 0.75\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "0wx96wXKE3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_rf)\n",
        "\n",
        "f1_best_rf = f1_score(y_test, y_pred_best_rf)\n",
        "print(\"f1-score with Best Model:\", f1_best_rf)\n",
        "\n",
        "auc_best_rf = roc_auc_score(y_test, y_pred_best_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_rf)\n",
        "\n",
        "classification_rep_best_rf = classification_report(y_test, y_pred_best_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHb1549mE47B",
        "outputId": "8c51b8d2-c6e8-4d5d-ee58-a6ce08073ced"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(min_samples_split=5, random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.875\n",
            "f1-score with Best Model: 0.923076923076923\n",
            "AUC with Best Model: 0.75\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "HKj2XQr1E69t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_linear = accuracy_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_linear)\n",
        "\n",
        "f1_best_svm_linear = f1_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_linear)\n",
        "\n",
        "y_scores_best_svm = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_linear = roc_auc_score(y_test, y_scores_best_svm)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_linear)\n",
        "\n",
        "classification_rep_best_svm_linear = classification_report(y_test, y_pred_best_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_linear)"
      ],
      "metadata": {
        "id": "yf_9r7aPE8me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031ee903-59fe-4d2e-90a1-beab6b6ee7a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.875\n",
            "f1-score with Best Model: 0.923076923076923\n",
            "AUC with Best Model: 0.9166666666666667\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "12jDiPduE-tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_poly = accuracy_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_poly)\n",
        "\n",
        "f1_best_svm_poly = f1_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_poly)\n",
        "\n",
        "y_scores_best_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_poly = roc_auc_score(y_test, y_scores_best_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_poly)\n",
        "\n",
        "classification_rep_best_svm_poly = classification_report(y_test, y_pred_best_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_poly)"
      ],
      "metadata": {
        "id": "5hRRw1dsFARi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e070b9ed-8ea2-455f-a5b6-4acd138addbd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 3, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "f1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.8333333333333333\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "VxtdgCiDFCUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_xgb)\n",
        "\n",
        "f1_best_xgb = f1_score(y_test, y_pred_best_xgb)\n",
        "print(\"f1-score with Best Model:\", f1_best_xgb)\n",
        "\n",
        "auc_best_xgb = roc_auc_score(y_test, y_pred_best_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_xgb)\n",
        "\n",
        "classification_rep_best_xgb = classification_report(y_test, y_pred_best_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_xgb)"
      ],
      "metadata": {
        "id": "_8x8Y9q8FD2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c324945e-3390-41b9-fd43-a0d1e9f559f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "f1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.5\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paretic-Side"
      ],
      "metadata": {
        "id": "uQNVk_1LFKXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "VDW4v6BlFIim"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상수항 없는 식\n",
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1','PC7','PC17']]\n",
        "y = par['score']\n",
        "import statsmodels.api as sm\n",
        "reg = sm.Logit(y,X).fit()\n",
        "print(reg.summary())\n",
        "print(np.exp(reg.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwGMcGUdt2dx",
        "outputId": "d3c34a65-e9ba-41d3-9c31-ca5480599814"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.493811\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   No. Observations:                   19\n",
            "Model:                          Logit   Df Residuals:                       16\n",
            "Method:                           MLE   Df Model:                            2\n",
            "Date:                Wed, 24 Jan 2024   Pseudo R-squ.:                  0.1432\n",
            "Time:                        07:47:40   Log-Likelihood:                -9.3824\n",
            "converged:                       True   LL-Null:                       -10.950\n",
            "Covariance Type:            nonrobust   LLR p-value:                    0.2085\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "PC1           -0.0217      0.013     -1.681      0.093      -0.047       0.004\n",
            "PC7            0.1078      0.064      1.674      0.094      -0.018       0.234\n",
            "PC17           0.1301      0.126      1.029      0.303      -0.118       0.378\n",
            "==============================================================================\n",
            "PC1     0.978551\n",
            "PC7     1.113818\n",
            "PC17    1.138910\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PC17이 유의하지 않으므로 PC17 제거 후 다시\n",
        "\n",
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1','PC7']]\n",
        "y = par['score']\n",
        "import statsmodels.api as sm\n",
        "reg = sm.Logit(y,X).fit()\n",
        "print(reg.summary())\n",
        "print(np.exp(reg.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVwgHx_axW69",
        "outputId": "1043d151-51a6-4015-e2c1-4fd822f201a8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.532142\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  score   No. Observations:                   19\n",
            "Model:                          Logit   Df Residuals:                       17\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Wed, 24 Jan 2024   Pseudo R-squ.:                 0.07668\n",
            "Time:                        07:47:40   Log-Likelihood:                -10.111\n",
            "converged:                       True   LL-Null:                       -10.950\n",
            "Covariance Type:            nonrobust   LLR p-value:                    0.1950\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "PC1           -0.0183      0.011     -1.649      0.099      -0.040       0.003\n",
            "PC7            0.0954      0.061      1.570      0.117      -0.024       0.215\n",
            "==============================================================================\n",
            "PC1    0.981836\n",
            "PC7    1.100110\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 상수항 추가\n",
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1','PC7','PC17']]\n",
        "y = par['score']\n",
        "X = sm.add_constant(X,has_constant=\"add\")\n",
        "logit = sm.Logit(y, X)\n",
        "result = logit.fit()\n",
        "print(result.summary2())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY3E136RukTR",
        "outputId": "2d38d2c4-3950-447d-b180-41fea09e9410"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.390431\n",
            "         Iterations 7\n",
            "                        Results: Logit\n",
            "===============================================================\n",
            "Model:              Logit            Method:           MLE     \n",
            "Dependent Variable: score            Pseudo R-squared: 0.323   \n",
            "Date:               2024-01-24 07:47 AIC:              22.8364 \n",
            "No. Observations:   19               BIC:              26.6141 \n",
            "Df Model:           3                Log-Likelihood:   -7.4182 \n",
            "Df Residuals:       15               LL-Null:          -10.950 \n",
            "Converged:          1.0000           LLR p-value:      0.069875\n",
            "No. Iterations:     7.0000           Scale:            1.0000  \n",
            "-----------------------------------------------------------------\n",
            "          Coef.    Std.Err.     z      P>|z|     [0.025    0.975]\n",
            "-----------------------------------------------------------------\n",
            "const     6.1671     3.5323   1.7459   0.0808   -0.7561   13.0903\n",
            "PC1       0.0937     0.0656   1.4287   0.1531   -0.0348    0.2222\n",
            "PC7       0.0703     0.0663   1.0596   0.2893   -0.0597    0.2003\n",
            "PC17      0.1776     0.1729   1.0274   0.3042   -0.1612    0.5165\n",
            "===============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 상수항 추가했을때 PC7,PC17 유의하지 않음\n",
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1']]\n",
        "y = par['score']\n",
        "import statsmodels.api as sm\n",
        "X = sm.add_constant(X,has_constant=\"add\")\n",
        "logit = sm.Logit(y, X)\n",
        "result = logit.fit()\n",
        "print(result.summary2())\n",
        "print(np.exp(result.params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5XZLu0Gx3fX",
        "outputId": "ebb8ddfc-b1cb-43df-acc6-b9b333dceba5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.453182\n",
            "         Iterations 6\n",
            "                        Results: Logit\n",
            "===============================================================\n",
            "Model:              Logit            Method:           MLE     \n",
            "Dependent Variable: score            Pseudo R-squared: 0.214   \n",
            "Date:               2024-01-24 07:47 AIC:              21.2209 \n",
            "No. Observations:   19               BIC:              23.1098 \n",
            "Df Model:           1                Log-Likelihood:   -8.6105 \n",
            "Df Residuals:       17               LL-Null:          -10.950 \n",
            "Converged:          1.0000           LLR p-value:      0.030519\n",
            "No. Iterations:     6.0000           Scale:            1.0000  \n",
            "-----------------------------------------------------------------\n",
            "          Coef.    Std.Err.     z      P>|z|     [0.025    0.975]\n",
            "-----------------------------------------------------------------\n",
            "const     6.9288     3.2385   2.1395   0.0324    0.5814   13.2761\n",
            "PC1       0.1159     0.0613   1.8915   0.0586   -0.0042    0.2361\n",
            "===============================================================\n",
            "\n",
            "const    1021.240245\n",
            "PC1         1.122936\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1','PC7','PC17']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "mo2TiT7XFNpK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "djXq0aT_FPZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_par_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_par_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr_ps = accuracy_score(y_test, y_pred_par_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr_ps)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr_ps = f1_score(y_test, y_pred_par_lr)\n",
        "print(\"f1-score:\", f1_lr_ps)\n",
        "\n",
        "# AUC 계산\n",
        "auc_lr_ps = roc_auc_score(y_test,y_pred_par_lr)\n",
        "print(\"AUC:\",auc_lr_ps)\n",
        "\n",
        "\n",
        "classification_rep_lr = classification_report(y_test, y_pred_par_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "id": "g_b1Zd9RFPtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837fe93a-dacc-4d64-b875-0b332c40d630"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [1 5]]\n",
            "Test Accuracy: 0.75\n",
            "f1-score: 0.8333333333333334\n",
            "AUC: 0.6666666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.67      0.67      0.67         8\n",
            "weighted avg       0.75      0.75      0.75         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic RandomForest"
      ],
      "metadata": {
        "id": "rLK_r_D3FRnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# 최적의 모델로 테스트 데이터에 대한 예측 수행\n",
        "y_pred_best_par_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_rf = accuracy_score(y_test, y_pred_best_par_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_rf)\n",
        "\n",
        "f1_best_par_rf = f1_score(y_test, y_pred_best_par_rf)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_rf)\n",
        "\n",
        "auc_best_par_rf = roc_auc_score(y_test, y_pred_best_par_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_par_rf)\n",
        "\n",
        "classification_rep_best_par_rf = classification_report(y_test, y_pred_best_par_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_rf)"
      ],
      "metadata": {
        "id": "BO-P30jvFTxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7029c93e-ee9c-4f65-a0b4-690a4d38b677"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[2 0]\n",
            " [2 4]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8\n",
            "AUC with Best Model: 0.8333333333333333\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.75      0.83      0.73         8\n",
            "weighted avg       0.88      0.75      0.77         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Linear"
      ],
      "metadata": {
        "id": "HqpvJiFgFWBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_linear = accuracy_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_linear)\n",
        "\n",
        "f1_best_par_svm_linear = f1_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_linear)\n",
        "\n",
        "y_scores_best_par_svm_linear = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_linear = roc_auc_score(y_test, y_scores_best_par_svm_linear)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_linear)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "id": "4va66LsEFXpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31884b0-ade5-4ead-f731-2fda6ea43d9b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[2 0]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 1.0\n",
            "F1-score with Best Model: 1.0\n",
            "AUC with Best Model: 1.0\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Poly"
      ],
      "metadata": {
        "id": "nzoKLK50FZ-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_poly = accuracy_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_poly)\n",
        "\n",
        "f1_best_par_svm_poly = f1_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_poly)\n",
        "\n",
        "y_scores_best_par_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_poly = roc_auc_score(y_test, y_scores_best_par_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_poly)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "id": "1K5jQ3mTFb6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1cb218-ce20-4764-fb8b-f55ed7fe3fa4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 1.0\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic XGBoost"
      ],
      "metadata": {
        "id": "8Erp4HXJFehN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_xgb = accuracy_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_xgb)\n",
        "\n",
        "f1_best_par_xgb = f1_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_xgb)\n",
        "\n",
        "auc_best_par_xgb = roc_auc_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_par_xgb)\n",
        "\n",
        "classification_rep_best_par_xgb = classification_report(y_test, y_pred_best_par_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_xgb)"
      ],
      "metadata": {
        "id": "dklVCvhYFgO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef33686-1391-4048-aba1-2afc06574669"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.5\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}