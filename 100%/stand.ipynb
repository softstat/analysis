{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqm2kBlYprG4UHK7foJoL9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So9eFOLFEP4c",
        "outputId": "0433c62f-e492-43ef-cf8d-95adf72bb937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CpMUNk_EX1i",
        "outputId": "d1863ece-a960-4445-f270-5ade2c3c5512"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "id": "tV22sB9gEYzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269b06ac-1fa0-4c3a-e693-04d691f5f239"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfv4bZCEaEf",
        "outputId": "0ab95d5c-49c5-4043-e15d-12e3b9dc757f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('stand/stand.csv')\n",
        "PRC = pd.read_csv('stand/stand_par.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "lSeKq_G5EbHF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y3d0mefjEjUT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "FMdzcvvXEmLp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del score[0]\n",
        "del score[1]\n",
        "del score[2]\n",
        "del score[3]\n",
        "del score[7]\n",
        "del score[9]\n",
        "del score[10]\n",
        "del score[13]\n",
        "del score[15]\n",
        "del score[16]\n",
        "del score[17]\n",
        "del score[18]\n",
        "del score[19]\n",
        "del score[20]\n",
        "del score[21]\n",
        "del score[22]\n",
        "del score[23]\n",
        "del score[24]\n",
        "del score[25]\n",
        "del score[26]\n",
        "del score[27]\n",
        "del score[31]\n",
        "del score[34]\n",
        "del score[36]\n",
        "del score[39]\n",
        "del score[44]\n",
        "del score[45]\n"
      ],
      "metadata": {
        "id": "BgyCQsxyEoVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK73bpUsEqMc",
        "outputId": "dc6cb318-ae0e-4fba-8320-90ba6b5aa494"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-paretic Side"
      ],
      "metadata": {
        "id": "R6saQXBUEtzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)\n",
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1NwUrLXErpM",
        "outputId": "983ef01b-7bc9-4829-88a8-fa496d3739cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = non.loc[:,['PC2','PC10','PC15']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "LkGOvGZTEvfm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 여기서 부터 다시"
      ],
      "metadata": {
        "id": "2-AQR-vUHjQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "z13gQSGCE0mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "print(\"f1-score:\", f1_lr)\n",
        "\n",
        "# auc 계산\n",
        "auc_lr = roc_auc_score(y_test,y_pred_lr)\n",
        "print(\"AUC:\",auc_lr)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El6jdv5QExYm",
        "outputId": "2d40cc3f-9f44-4cc3-f59b-b34a7b1f1cf9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy: 0.875\n",
            "f1-score: 0.923076923076923\n",
            "AUC: 0.75\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "0wx96wXKE3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_rf)\n",
        "\n",
        "f1_best_rf = f1_score(y_test, y_pred_best_rf)\n",
        "print(\"f1-score with Best Model:\", f1_best_rf)\n",
        "\n",
        "auc_best_rf = roc_auc_score(y_test, y_pred_best_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_rf)\n",
        "\n",
        "classification_rep_best_rf = classification_report(y_test, y_pred_best_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHb1549mE47B",
        "outputId": "94db2b5c-8418-44cf-c2c3-e24556a4cf22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(min_samples_split=5, random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.875\n",
            "f1-score with Best Model: 0.923076923076923\n",
            "AUC with Best Model: 0.75\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "HKj2XQr1E69t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_linear = accuracy_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_linear)\n",
        "\n",
        "f1_best_svm_linear = f1_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_linear)\n",
        "\n",
        "y_scores_best_svm = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_linear = roc_auc_score(y_test, y_scores_best_svm)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_linear)\n",
        "\n",
        "classification_rep_best_svm_linear = classification_report(y_test, y_pred_best_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_linear)"
      ],
      "metadata": {
        "id": "yf_9r7aPE8me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3966f7a5-4552-4896-9543-e50fa189491f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[1 1]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.875\n",
            "f1-score with Best Model: 0.923076923076923\n",
            "AUC with Best Model: 0.9166666666666667\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.88         8\n",
            "   macro avg       0.93      0.75      0.79         8\n",
            "weighted avg       0.89      0.88      0.86         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "12jDiPduE-tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_poly = accuracy_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_poly)\n",
        "\n",
        "f1_best_svm_poly = f1_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_poly)\n",
        "\n",
        "y_scores_best_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_poly = roc_auc_score(y_test, y_scores_best_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_poly)\n",
        "\n",
        "classification_rep_best_svm_poly = classification_report(y_test, y_pred_best_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_poly)"
      ],
      "metadata": {
        "id": "5hRRw1dsFARi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b48326-a3bc-4c98-ad06-81f2dba737c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 3, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "f1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.8333333333333333\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "VxtdgCiDFCUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_xgb)\n",
        "\n",
        "f1_best_xgb = f1_score(y_test, y_pred_best_xgb)\n",
        "print(\"f1-score with Best Model:\", f1_best_xgb)\n",
        "\n",
        "auc_best_xgb = roc_auc_score(y_test, y_pred_best_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_xgb)\n",
        "\n",
        "classification_rep_best_xgb = classification_report(y_test, y_pred_best_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_xgb)"
      ],
      "metadata": {
        "id": "_8x8Y9q8FD2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74964a6-fe19-4f8e-f9fe-2885ab8fa0ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "f1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.5\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paretic-Side"
      ],
      "metadata": {
        "id": "uQNVk_1LFKXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "VDW4v6BlFIim"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC7']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "mo2TiT7XFNpK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "djXq0aT_FPZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_par_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_par_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr_ps = accuracy_score(y_test, y_pred_par_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr_ps)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr_ps = f1_score(y_test, y_pred_par_lr)\n",
        "print(\"f1-score:\", f1_lr_ps)\n",
        "\n",
        "# AUC 계산\n",
        "auc_lr_ps = roc_auc_score(y_test,y_pred_par_lr)\n",
        "print(\"AUC:\",auc_lr_ps)\n",
        "\n",
        "\n",
        "classification_rep_lr = classification_report(y_test, y_pred_par_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "id": "g_b1Zd9RFPtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72e5703-86ed-4969-f33e-0e498af23d3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy: 0.75\n",
            "f1-score: 0.8571428571428571\n",
            "AUC: 0.5\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic RandomForest"
      ],
      "metadata": {
        "id": "rLK_r_D3FRnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# 최적의 모델로 테스트 데이터에 대한 예측 수행\n",
        "y_pred_best_par_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_rf = accuracy_score(y_test, y_pred_best_par_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_rf)\n",
        "\n",
        "f1_best_par_rf = f1_score(y_test, y_pred_best_par_rf)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_rf)\n",
        "\n",
        "auc_best_par_rf = roc_auc_score(y_test, y_pred_best_par_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_par_rf)\n",
        "\n",
        "classification_rep_best_par_rf = classification_report(y_test, y_pred_best_par_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_rf)"
      ],
      "metadata": {
        "id": "BO-P30jvFTxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ede5893-7a26-4733-a98a-04de84f1af73"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(min_samples_split=5, n_estimators=200, random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Confusion Matrix:\n",
            " [[2 0]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 1.0\n",
            "F1-score with Best Model: 1.0\n",
            "AUC with Best Model: 1.0\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Linear"
      ],
      "metadata": {
        "id": "HqpvJiFgFWBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_linear = accuracy_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_linear)\n",
        "\n",
        "f1_best_par_svm_linear = f1_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_linear)\n",
        "\n",
        "y_scores_best_par_svm_linear = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_linear = roc_auc_score(y_test, y_scores_best_par_svm_linear)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_linear)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "id": "4va66LsEFXpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a29fa50-e802-44b4-9ccc-417ce57d58f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.0\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Poly"
      ],
      "metadata": {
        "id": "nzoKLK50FZ-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_poly = accuracy_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_poly)\n",
        "\n",
        "f1_best_par_svm_poly = f1_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_poly)\n",
        "\n",
        "y_scores_best_par_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_poly = roc_auc_score(y_test, y_scores_best_par_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_poly)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "id": "1K5jQ3mTFb6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc60a97b-c8c5-4ce5-fcb6-2342ee3a5cc1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.08333333333333333\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic XGBoost"
      ],
      "metadata": {
        "id": "8Erp4HXJFehN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_xgb = accuracy_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_xgb)\n",
        "\n",
        "f1_best_par_xgb = f1_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_xgb)\n",
        "\n",
        "auc_best_par_xgb = roc_auc_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_par_xgb)\n",
        "\n",
        "classification_rep_best_par_xgb = classification_report(y_test, y_pred_best_par_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_xgb)"
      ],
      "metadata": {
        "id": "dklVCvhYFgO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc85ee12-0d47-49cf-b8cf-9893c66ce543"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 6]]\n",
            "Test Accuracy with Best Model: 0.75\n",
            "F1-score with Best Model: 0.8571428571428571\n",
            "AUC with Best Model: 0.5\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         6\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.38      0.50      0.43         8\n",
            "weighted avg       0.56      0.75      0.64         8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}