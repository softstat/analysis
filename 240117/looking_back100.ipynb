{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcw97BHRv2CnIe/nK7j08e"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lUoSmei37Ii",
        "outputId": "8ca4b9ba-b581-4adf-f914-d4b324db18cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLvWKmPZ4Gcx",
        "outputId": "5f9cb695-c0ac-4cb6-d9be-192fa2dc4bd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('looking_back/100%/look100.csv')\n",
        "PRC = pd.read_csv('looking_back/100%/look_par100.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "QoQ_SxoA4HeZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UUGnxcaz4UQi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "1cw2F28w4WXY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = score.dropna()\n",
        "del score[0]\n",
        "del score[1]\n",
        "del score[9]\n",
        "del score[18]"
      ],
      "metadata": {
        "id": "Le80vrxz4Xkm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwIre7e24ZWZ",
        "outputId": "502b5465-382f-43f6-c289-5e4a593fd760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Paretic Side"
      ],
      "metadata": {
        "id": "IPN8Dnrq4bti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)\n",
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJeGnM_U4azw",
        "outputId": "8f5727d4-a35c-4a32-a5f5-5db21aaf86b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25',\n",
              "       'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34',\n",
              "       'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC6','PC11','PC18','PC22','PC24','PC37']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "hdheklZg4e5E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "UD8y63yG4nX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drFcjEb84mUC",
        "outputId": "26d6445a-9de3-4ee4-fbe6-7bae71db4f90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.2332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "SsZI_lKg4pzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOr3_wDE4qd_",
        "outputId": "b496cde2-8a32-4dd8-c2de-fd29194b5316"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "v7R1ezzX4r4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a09-OvcI4ssk",
        "outputId": "37f5fa11-9639-40f0-c88a-72fb2ab52529"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "mz7eOyHK4uTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7kgIS8K4uIT",
        "outputId": "f1b8a4d7-9563-4976-8856-e7b2d045505d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.5666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "nnZ4o1J94wfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cTYXg7A4xIL",
        "outputId": "f13092fe-4190-451b-b0a0-0c46a68863cb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.5166000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paretic Side"
      ],
      "metadata": {
        "id": "-TGIFKSK4yi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "jeylE17l4zn3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC1','PC3','PC8','PC12','PC19','PC21','PC25']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "bg_SXXHo41Ez"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "jcvHApYg49zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvqROsp14-w0",
        "outputId": "b5683518-dd20-4cbe-a0aa-9c06ed3f8555"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7501999999999999\n",
            "Average F1-score: 0.8113999999999999\n",
            "Average AUC: 0.33340000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "O6MVDRVK5AlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vhCSRF65BTN",
        "outputId": "e741ccc8-38b3-453c-d44d-74d6221cae59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7667999999999999\n",
            "Average Precision: 0.7667999999999999\n",
            "Average F1-score: 0.8628\n",
            "Average AUC: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "EaE4eGaT5CsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2R59KQm5DUa",
        "outputId": "de014a73-2f17-453b-c0e0-9a1f8ecd2edb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.4668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "HJlVYTEi5FC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4TnIjnx5FsP",
        "outputId": "061c5db5-0f17-4c17-a560-aa10941cd075"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.33340000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "ZzcRKTCQ5HTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT9DCh0e5H-d",
        "outputId": "74f967be-1590-4542-87fe-f68f2dd82051"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6502000000000001\n",
            "Average Precision: 0.6836\n",
            "Average F1-score: 0.7847999999999999\n",
            "Average AUC: 0.7\n"
          ]
        }
      ]
    }
  ]
}