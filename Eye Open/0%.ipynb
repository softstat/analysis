{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhmA9YnVVwp0nQaeC9pHzp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to8SnHK4rra2",
        "outputId": "056102f7-7ffa-472a-8855-6e9b1fa5aa50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pIv5gztrvDq",
        "outputId": "e55fd725-6d39-4a14-fdf2-238fdd47b198"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('eye_open/0%/eye_open0.csv')\n",
        "PRC = pd.read_csv('eye_open/0%/eye_open_par0.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "jMtarJ-8ryRZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ttxYXedOsUpo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "vU_kehM6sWHB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = score.dropna()\n",
        "del score[0]\n",
        "del score[15]"
      ],
      "metadata": {
        "id": "0ctXHB4AsXT5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0iuTvHesYnJ",
        "outputId": "69533bd4-3bb4-45a1-8a86-adda8af13d17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Paretic Side"
      ],
      "metadata": {
        "id": "JYxuGc85sdV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "Rr33j4M-sepA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCy30yZWsiWr",
        "outputId": "a897feb8-4b62-412c-fbfc-02eb508abaca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25',\n",
              "       'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34',\n",
              "       'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41', 'PC42', 'PC43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = non.loc[:,['PC6','PC9','PC14','PC17','PC19','PC20','PC23','PC33']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "5XsECMDxsjzi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "XT5ILw6rqyfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "print(\"f1-score:\", f1_lr)\n",
        "\n",
        "# auc 계산\n",
        "auc_lr = roc_auc_score(y_test,y_pred_lr)\n",
        "print(\"AUC:\",auc_lr)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZYwotvlsqQP",
        "outputId": "424ee878-bff5-4f20-f4a3-6806b0b228e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 2  4]\n",
            " [ 1 11]]\n",
            "Test Accuracy: 0.7222222222222222\n",
            "f1-score: 0.8148148148148148\n",
            "AUC: 0.625\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44         6\n",
            "           1       0.73      0.92      0.81        12\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.70      0.62      0.63        18\n",
            "weighted avg       0.71      0.72      0.69        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "PMcQWhKDq0b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_rf)\n",
        "\n",
        "f1_best_rf = f1_score(y_test, y_pred_best_rf)\n",
        "print(\"f1-score with Best Model:\", f1_best_rf)\n",
        "\n",
        "auc_best_rf = roc_auc_score(y_test, y_pred_best_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_rf)\n",
        "\n",
        "classification_rep_best_rf = classification_report(y_test, y_pred_best_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXprZZBTstq2",
        "outputId": "b9c52883-5173-4f38-ba4e-79a6178043c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[ 2  4]\n",
            " [ 2 10]]\n",
            "Test Accuracy with Best Model: 0.6666666666666666\n",
            "f1-score with Best Model: 0.7692307692307692\n",
            "AUC with Best Model: 0.5833333333333335\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         6\n",
            "           1       0.71      0.83      0.77        12\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.61      0.58      0.58        18\n",
            "weighted avg       0.64      0.67      0.65        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "15rrhc6Aq7s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_linear = accuracy_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_linear)\n",
        "\n",
        "f1_best_svm_linear = f1_score(y_test, y_pred_best_svm_linear)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_linear)\n",
        "\n",
        "y_scores_best_svm = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_linear = roc_auc_score(y_test, y_scores_best_svm)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_linear)\n",
        "\n",
        "classification_rep_best_svm_linear = classification_report(y_test, y_pred_best_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-SSGaqysviI",
        "outputId": "daf22e11-03e3-4c52-c153-0c851d596a22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=1, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 1, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[ 2  4]\n",
            " [ 1 11]]\n",
            "Test Accuracy with Best Model: 0.7222222222222222\n",
            "f1-score with Best Model: 0.8148148148148148\n",
            "AUC with Best Model: 0.5277777777777778\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44         6\n",
            "           1       0.73      0.92      0.81        12\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.70      0.62      0.63        18\n",
            "weighted avg       0.71      0.72      0.69        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "EgbOKPxVq9E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_svm_poly = accuracy_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_svm_poly)\n",
        "\n",
        "f1_best_svm_poly = f1_score(y_test, y_pred_best_svm_poly)\n",
        "print(\"f1-score with Best Model:\", f1_best_svm_poly)\n",
        "\n",
        "y_scores_best_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_svm_poly = roc_auc_score(y_test, y_scores_best_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_svm_poly)\n",
        "\n",
        "classification_rep_best_svm_poly = classification_report(y_test, y_pred_best_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_svm_poly)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "938p-FVmsxSQ",
        "outputId": "ec80d19a-4901-4712-9929-e2bf97ac573d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=10, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 10, 'degree': 3, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[ 1  5]\n",
            " [ 1 11]]\n",
            "Test Accuracy with Best Model: 0.6666666666666666\n",
            "f1-score with Best Model: 0.7857142857142857\n",
            "AUC with Best Model: 0.6111111111111112\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.17      0.25         6\n",
            "           1       0.69      0.92      0.79        12\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.59      0.54      0.52        18\n",
            "weighted avg       0.62      0.67      0.61        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "uUliiEx5rA1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_xgb)\n",
        "\n",
        "f1_best_xgb = f1_score(y_test, y_pred_best_xgb)\n",
        "print(\"f1-score with Best Model:\", f1_best_xgb)\n",
        "\n",
        "auc_best_xgb = roc_auc_score(y_test, y_pred_best_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_xgb)\n",
        "\n",
        "classification_rep_best_xgb = classification_report(y_test, y_pred_best_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrBuHHD1szPa",
        "outputId": "81931c68-d636-4ddd-e9ff-4b2bd00fab03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
            "Confusion Matrix:\n",
            " [[3 3]\n",
            " [3 9]]\n",
            "Test Accuracy with Best Model: 0.6666666666666666\n",
            "f1-score with Best Model: 0.75\n",
            "AUC with Best Model: 0.625\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         6\n",
            "           1       0.75      0.75      0.75        12\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.62      0.62      0.62        18\n",
            "weighted avg       0.67      0.67      0.67        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paretic Side"
      ],
      "metadata": {
        "id": "Cry3Tn0Ss2M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "sV6Djkmas3X-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC4','PC7','PC13','PC15','PC16','PC17','PC29','PC32','PC35']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "6VCNpM_zs6ag"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "uzuGmeS-rGOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_par_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_par_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr_ps = accuracy_score(y_test, y_pred_par_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr_ps)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr_ps = f1_score(y_test, y_pred_par_lr)\n",
        "print(\"f1-score:\", f1_lr_ps)\n",
        "\n",
        "# AUC 계산\n",
        "auc_lr_ps = roc_auc_score(y_test,y_pred_par_lr)\n",
        "print(\"AUC:\",auc_lr_ps)\n",
        "\n",
        "\n",
        "classification_rep_lr = classification_report(y_test, y_pred_par_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41-rJTIttBqx",
        "outputId": "7cce43aa-1a6b-4d2b-a4a4-5663f1eeac6b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 4  2]\n",
            " [ 1 11]]\n",
            "Test Accuracy: 0.8333333333333334\n",
            "f1-score: 0.8799999999999999\n",
            "AUC: 0.7916666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73         6\n",
            "           1       0.85      0.92      0.88        12\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.82      0.79      0.80        18\n",
            "weighted avg       0.83      0.83      0.83        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "aQzApRQJrIOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# 최적의 모델로 테스트 데이터에 대한 예측 수행\n",
        "y_pred_best_par_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_rf)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_rf = accuracy_score(y_test, y_pred_best_par_rf)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_rf)\n",
        "\n",
        "f1_best_par_rf = f1_score(y_test, y_pred_best_par_rf)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_rf)\n",
        "\n",
        "auc_best_par_rf = roc_auc_score(y_test, y_pred_best_par_rf)\n",
        "print(\"AUC with Best Model:\", auc_best_par_rf)\n",
        "\n",
        "classification_rep_best_par_rf = classification_report(y_test, y_pred_best_par_rf)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrAIMH4ctDNQ",
        "outputId": "943fbada-3f3a-45b2-f780-b2263bb90ea9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Model: RandomForestClassifier(min_samples_leaf=2, n_estimators=200, random_state=123)\n",
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Confusion Matrix:\n",
            " [[ 1  5]\n",
            " [ 0 12]]\n",
            "Test Accuracy with Best Model: 0.7222222222222222\n",
            "F1-score with Best Model: 0.8275862068965517\n",
            "AUC with Best Model: 0.5833333333333333\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.17      0.29         6\n",
            "           1       0.71      1.00      0.83        12\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.85      0.58      0.56        18\n",
            "weighted avg       0.80      0.72      0.65        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "L-14VJPrrOX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_linear = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_linear = accuracy_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_linear)\n",
        "\n",
        "f1_best_par_svm_linear = f1_score(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_linear)\n",
        "\n",
        "y_scores_best_par_svm_linear = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_linear = roc_auc_score(y_test, y_scores_best_par_svm_linear)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_linear)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_linear)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3jD_9lItE7n",
        "outputId": "8078a04f-5d09-4c07-d66f-17ca33f49db6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=10, degree=2, kernel='linear', random_state=123)\n",
            "Best Hyperparameters: {'C': 10, 'degree': 2, 'kernel': 'linear'}\n",
            "Confusion Matrix:\n",
            " [[ 4  2]\n",
            " [ 2 10]]\n",
            "Test Accuracy with Best Model: 0.7777777777777778\n",
            "F1-score with Best Model: 0.8333333333333334\n",
            "AUC with Best Model: 0.7777777777777779\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         6\n",
            "           1       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.75      0.75      0.75        18\n",
            "weighted avg       0.78      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "0TP05BNirSpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best SVM Model:\", best_svm_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_svm_poly = best_svm_model.predict(X_test)\n",
        "\n",
        "# 성능 메트릭 계산\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_svm_poly = accuracy_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_svm_poly)\n",
        "\n",
        "f1_best_par_svm_poly = f1_score(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_svm_poly)\n",
        "\n",
        "y_scores_best_par_svm_poly = best_svm_model.decision_function(X_test)\n",
        "auc_best_par_svm_poly = roc_auc_score(y_test, y_scores_best_par_svm_poly)\n",
        "print(\"AUC with Best Model:\", auc_best_par_svm_poly)\n",
        "\n",
        "classification_rep_best_par_svm = classification_report(y_test, y_pred_best_par_svm_poly)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwWV0uatG92",
        "outputId": "f3e56ccf-7a85-46b1-9d02-67a895c4b29b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Model: SVC(C=0.1, degree=2, kernel='poly', random_state=123)\n",
            "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'poly'}\n",
            "Confusion Matrix:\n",
            " [[ 0  6]\n",
            " [ 0 12]]\n",
            "Test Accuracy with Best Model: 0.6666666666666666\n",
            "F1-score with Best Model: 0.8\n",
            "AUC with Best Model: 0.4444444444444445\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         6\n",
            "           1       0.67      1.00      0.80        12\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.33      0.50      0.40        18\n",
            "weighted avg       0.44      0.67      0.53        18\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "UXqQmllVrYu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best XGBoost Model:\", best_xgb_model)\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "\n",
        "y_pred_best_par_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_best_par_xgb)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "\n",
        "accuracy_best_par_xgb = accuracy_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"Test Accuracy with Best Model:\", accuracy_best_par_xgb)\n",
        "\n",
        "f1_best_par_xgb = f1_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"F1-score with Best Model:\", f1_best_par_xgb)\n",
        "\n",
        "auc_best_par_xgb = roc_auc_score(y_test, y_pred_best_par_xgb)\n",
        "print(\"AUC with Best Model:\", auc_best_par_xgb)\n",
        "\n",
        "classification_rep_best_par_xgb = classification_report(y_test, y_pred_best_par_xgb)\n",
        "print(\"Classification Report with Best Model:\\n\", classification_rep_best_par_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY2M21NgtI7A",
        "outputId": "b2924893-cb0f-4395-e504-d95670f4f282"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Model: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=123, ...)\n",
            "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
            "Confusion Matrix:\n",
            " [[ 1  5]\n",
            " [ 1 11]]\n",
            "Test Accuracy with Best Model: 0.6666666666666666\n",
            "F1-score with Best Model: 0.7857142857142857\n",
            "AUC with Best Model: 0.5416666666666666\n",
            "Classification Report with Best Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.17      0.25         6\n",
            "           1       0.69      0.92      0.79        12\n",
            "\n",
            "    accuracy                           0.67        18\n",
            "   macro avg       0.59      0.54      0.52        18\n",
            "weighted avg       0.62      0.67      0.61        18\n",
            "\n"
          ]
        }
      ]
    }
  ]
}