{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpbT/D9tqMK53LzdJYO3YI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D8nvyByHMdo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ac159e-0a5f-4911-9313-914d05384846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "id": "9kPXTNTpMxNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed0dae6-33fa-450b-d5ca-4368d4a04454"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "id": "2c-wURswMzDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18baee29-aec6-44e0-a15a-0a1a4c9ac6a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data"
      ],
      "metadata": {
        "id": "dYT2frTcM0Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcfaea0-17c1-4048-f776-b269ab1452f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('eye_open/eye_open.csv')\n",
        "PRC = pd.read_csv('eye_open/eye_open_par.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "H495l95eM1aA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tK-SbXzIM_KN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "v-4kXHyjNBUX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "h_-Ax03yNCjd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = score.dropna()\n",
        "del score[0]\n",
        "del score[15]"
      ],
      "metadata": {
        "id": "vgOa5mUdNDuJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "7lE1PmRKNGsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270e5c35-4290-4702-f3b4-8dcbbe402f48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-paretic Side"
      ],
      "metadata": {
        "id": "XRFBqSDiNJra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)"
      ],
      "metadata": {
        "id": "kYLmKmkCNIY-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "umk2sz4eNLeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "id": "VzAkLxAzNMw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5854918-ba0f-4166-92e4-64e835b5fb01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25',\n",
              "       'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34',\n",
              "       'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41', 'PC42', 'PC43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC2','PC4','PC5','PC13','PC15','PC18','PC20','PC30','PC34']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "9UFAqPRDNQVm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "ROMx1stZNaTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "jvv2fJXuNbul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda41e3f-7ccf-4039-ee42-3f7e01e73368"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9\n",
            "Average Precision: 0.9\n",
            "Average F1-score: 0.9334\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "vo7QoR9WNfvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "lmikrD3oNg_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9414fe1-5206-4886-8e83-d6bca357a766"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7333999999999999\n",
            "Average Precision: 0.7333999999999999\n",
            "Average F1-score: 0.8362\n",
            "Average AUC: 0.7166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "auc3k4UcNk0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "5hrNf0PcNjPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5e9fe9-782d-4ec8-d34a-02294b088fb5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9\n",
            "Average Precision: 0.9\n",
            "Average F1-score: 0.9334\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "07wmvJ9DNoig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "YGkhRXjpNpzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43146645-a4b1-4560-a1c3-75b12a271f2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6668\n",
            "Average Precision: 0.6668\n",
            "Average F1-score: 0.7962\n",
            "Average AUC: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "4huXwBz4NtYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "HxcwYEEkNr7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43c2e3f-9093-4d02-9256-9be41ea4a140"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7666000000000001\n",
            "Average Precision: 0.7834\n",
            "Average F1-score: 0.8314\n",
            "Average AUC: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paretic-Side"
      ],
      "metadata": {
        "id": "TqlrYz9ENz_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "eAPHybSJN0Vv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC2','PC3','PC5','PC15','PC18','PC25','PC38']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "-ZQKOShFN1yP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "DzJLnLSROA5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "JEX72nanN-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44fa1eb-f080-40eb-c552-079d253ce801"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.65\n",
            "Average Precision: 0.7\n",
            "Average F1-score: 0.6268\n",
            "Average AUC: 0.6334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RandomForest"
      ],
      "metadata": {
        "id": "_alQodw_OEnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "lldlmfyZOHPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32b172d-a60a-431f-a46d-fd227291d216"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6666000000000001\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.7647999999999999\n",
            "Average AUC: 0.6168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM Linear"
      ],
      "metadata": {
        "id": "kNnf2CyoOJs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "_dMDbqFPOMCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d504d20-69df-4981-be2b-670def9c0907"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8\n",
            "Average Precision: 0.85\n",
            "Average F1-score: 0.8648\n",
            "Average AUC: 0.7668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM Poly"
      ],
      "metadata": {
        "id": "bC3OOqW7OOiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "5Uv9sbS_OPxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88690e38-e50a-43ec-d5ef-e6d2c0df6f29"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6668\n",
            "Average Precision: 0.6668\n",
            "Average F1-score: 0.7962\n",
            "Average AUC: 0.4166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost"
      ],
      "metadata": {
        "id": "Z1kbeG4GOR2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "dMmjV1cLOT2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f9f5c3-ebcb-4670-8db7-f8d2ac50b1ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7834\n",
            "Average Precision: 0.9\n",
            "Average F1-score: 0.8268000000000001\n",
            "Average AUC: 0.7333999999999999\n"
          ]
        }
      ]
    }
  ]
}