{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORl35Qx43UMjJp8EVifkPK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D8nvyByHMdo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8813194b-e499-430f-ceb3-2d99a177757f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "id": "9kPXTNTpMxNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880e2091-45ea-4c57-d98f-dfbcd0dfe3a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "id": "2c-wURswMzDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1efad7-9356-46dc-fcc0-c1e83a6b7587"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data"
      ],
      "metadata": {
        "id": "dYT2frTcM0Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a54f5aa-b897-4866-eecf-0b0c7ee8d4e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('eye_open/eye_open.csv')\n",
        "PRC = pd.read_csv('eye_open/eye_open_par.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "H495l95eM1aA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tK-SbXzIM_KN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "v-4kXHyjNBUX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "h_-Ax03yNCjd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = score.dropna()\n",
        "del score[0]\n",
        "del score[15]"
      ],
      "metadata": {
        "id": "vgOa5mUdNDuJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "7lE1PmRKNGsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a63fcd0-2b27-4d7d-fcd7-25d8fb300a0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-paretic Side"
      ],
      "metadata": {
        "id": "XRFBqSDiNJra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)"
      ],
      "metadata": {
        "id": "kYLmKmkCNIY-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "umk2sz4eNLeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "id": "VzAkLxAzNMw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f8c45d-f621-4b42-8337-c872ec75e601"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25',\n",
              "       'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34',\n",
              "       'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41', 'PC42', 'PC43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC2','PC13','PC15','PC18','PC20','PC34']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "9UFAqPRDNQVm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "ROMx1stZNaTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "print(\"f1-score:\", f1_lr)\n",
        "\n",
        "# auc 계산\n",
        "auc_lr = roc_auc_score(y_test,y_pred_lr)\n",
        "print(\"AUC:\",auc_lr)\n",
        "\n",
        "# 분류 보고서 출력\n",
        "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "id": "jvv2fJXuNbul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea3f111-2b5e-4873-8c24-31d870694c89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[5 1]\n",
            " [3 9]]\n",
            "Test Accuracy: 0.7777777777777778\n",
            "f1-score: 0.8181818181818182\n",
            "AUC: 0.7916666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.83      0.71         6\n",
            "           1       0.90      0.75      0.82        12\n",
            "\n",
            "    accuracy                           0.78        18\n",
            "   macro avg       0.76      0.79      0.77        18\n",
            "weighted avg       0.81      0.78      0.78        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "vo7QoR9WNfvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "lmikrD3oNg_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2759bbd-e927-456b-96ec-378300538483"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.8333999999999999\n",
            "Average Precision: 0.8168\n",
            "Average F1-score: 0.8914\n",
            "Average AUC: 0.7666000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "auc3k4UcNk0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "5hrNf0PcNjPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e49614-a60a-40a1-e2ae-10333ae820f7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.85\n",
            "Average Precision: 0.85\n",
            "Average F1-score: 0.9048\n",
            "Average AUC: 0.9334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "07wmvJ9DNoig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "YGkhRXjpNpzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37d6ee7-d810-462f-9ae6-761610fb9181"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.5666\n",
            "Average Precision: 0.65\n",
            "Average F1-score: 0.6848000000000001\n",
            "Average AUC: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "4huXwBz4NtYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "HxcwYEEkNr7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1657fb98-d2d3-44f0-b395-6103ce062cad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7666000000000001\n",
            "Average Precision: 0.7834\n",
            "Average F1-score: 0.8314\n",
            "Average AUC: 0.8333999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paretic-Side"
      ],
      "metadata": {
        "id": "TqlrYz9ENz_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "eAPHybSJN0Vv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC2','PC5','PC15','PC18','PC25','PC38']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "-ZQKOShFN1yP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "DzJLnLSROA5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_par_lr = lr_model.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_par_lr)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "# 정확도 계산\n",
        "accuracy_lr_ps = accuracy_score(y_test, y_pred_par_lr)\n",
        "print(\"Test Accuracy:\", accuracy_lr_ps)\n",
        "\n",
        "# f1-score 계산\n",
        "f1_lr_ps = f1_score(y_test, y_pred_par_lr)\n",
        "print(\"f1-score:\", f1_lr_ps)\n",
        "\n",
        "# AUC 계산\n",
        "auc_lr_ps = roc_auc_score(y_test,y_pred_par_lr)\n",
        "print(\"AUC:\",auc_lr_ps)\n",
        "\n",
        "\n",
        "classification_rep_lr = classification_report(y_test, y_pred_par_lr)\n",
        "print(\"Classification Report:\\n\", classification_rep_lr)"
      ],
      "metadata": {
        "id": "JEX72nanN-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ed0b6a-94c4-4c4a-e3ec-40aeaefd7b3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[4 2]\n",
            " [3 9]]\n",
            "Test Accuracy: 0.7222222222222222\n",
            "f1-score: 0.7826086956521738\n",
            "AUC: 0.7083333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.67      0.62         6\n",
            "           1       0.82      0.75      0.78        12\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.69      0.71      0.70        18\n",
            "weighted avg       0.74      0.72      0.73        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic RandomForest"
      ],
      "metadata": {
        "id": "_alQodw_OEnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "lldlmfyZOHPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a1227b-c8dc-48ea-c916-2b52f623567a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6666000000000001\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.7647999999999999\n",
            "Average AUC: 0.7333999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Linear"
      ],
      "metadata": {
        "id": "kNnf2CyoOJs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "_dMDbqFPOMCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0c6f20-1c58-40a6-cae3-078f7defb4b0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.5668\n",
            "Average Precision: 0.8333999999999999\n",
            "Average F1-score: 0.6336\n",
            "Average AUC: 0.5668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Poly"
      ],
      "metadata": {
        "id": "bC3OOqW7OOiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "5Uv9sbS_OPxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2db8845-4222-4829-d811-5ebb72a0d7a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6668\n",
            "Average Precision: 0.7167999999999999\n",
            "Average F1-score: 0.7847999999999999\n",
            "Average AUC: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic XGBoost"
      ],
      "metadata": {
        "id": "Z1kbeG4GOR2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "id": "dMmjV1cLOT2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298a94ec-1331-414d-ab5c-6a69c22f5999"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7834\n",
            "Average Precision: 0.9\n",
            "Average F1-score: 0.8268000000000001\n",
            "Average AUC: 0.7333999999999999\n"
          ]
        }
      ]
    }
  ]
}