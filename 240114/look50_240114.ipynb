{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV41z0T3J4zjJkYyv+Qne1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn4YSRKbfPaf",
        "outputId": "45b1f990-dc93-49b3-ee74-3d30f7e53b3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSiocrYfQSu",
        "outputId": "56661b2d-e724-42ac-e0e1-1f2d55c9fa62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-tQQQyY6fKck"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('looking_back/50%/look50.csv')\n",
        "PRC = pd.read_csv('looking_back/50%/look_par50.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "i8TtRGdAfS_Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "WIH7y4lbfVZg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = score.dropna()\n",
        "del score[0]\n",
        "del score[1]\n",
        "del score[9]\n",
        "del score[18]"
      ],
      "metadata": {
        "id": "ibwf7fmkfWzY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvvs-wtyfaDY",
        "outputId": "e72a6025-81d0-4272-ad28-f2de106b469b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Paretic Side"
      ],
      "metadata": {
        "id": "YZTURwocfdag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)\n",
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JrkUDKbfecT",
        "outputId": "1fcf49b9-edc1-49fd-c030-a2e4ca259d7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25',\n",
              "       'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34',\n",
              "       'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC5','PC20','PC27','PC33','PC41']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "xBBOjdBefj8P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "4Qwlv2718JaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSqkB3Pif6td",
        "outputId": "45173cde-f036-4c7a-f946-ad17d7d4720f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.5833999999999999\n",
            "Average Precision: 0.6668\n",
            "Average F1-score: 0.7\n",
            "Average AUC: 0.6666000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "pLFy4nDg8Lng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RZMSwqTf9Cm",
        "outputId": "61d5286e-9a13-485b-a16f-f3be672bcc16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.4668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "GsM0G19U8N3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3iuLHvif-52",
        "outputId": "d3f48c22-4ca1-4e97-f4b8-de2100b43975"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.6666000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "UR5KP5eC8RQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr14MAmmgBfP",
        "outputId": "1453e0b1-ada7-4221-95b4-c9e6be99c659"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.6334\n",
            "Average Precision: 0.6668\n",
            "Average F1-score: 0.7628\n",
            "Average AUC: 0.5334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "8eGInLc18Z5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cukVYuMKgC0X",
        "outputId": "d66260ac-c1fa-436c-f217-72847dbcd74e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.5668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paretic Side"
      ],
      "metadata": {
        "id": "-0byzGF_gI33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "LSklcM5_gKmY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC2','PC5','PC23','PC28','PC34','PC36','PC39']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "KmliLa1qgMCv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "GViJQaNX8jPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW0WKwjJgkGJ",
        "outputId": "33d11f85-bb91-4b10-ba32-d870358ff7b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7336\n",
            "Average F1-score: 0.8134\n",
            "Average AUC: 0.7333999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "Imoinapn8hd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjfs9nyAgmTm",
        "outputId": "628712f0-6d39-4bd9-ca99-b6022fbcfa71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.6668000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "9gEPqkP58lDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmkQxUDMgmum",
        "outputId": "5cbb927e-d10a-4bb0-8cae-a37bc53aa318"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "0T88lQiT8oS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBi1j5J9gork",
        "outputId": "aed14bb5-0aa6-4765-f7f1-6d455fca448e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7001999999999999\n",
            "Average F1-score: 0.8228\n",
            "Average AUC: 0.8333999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "KGqgix5e8sxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=5)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=5)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=5)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=5)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30eiDLaOgqkF",
        "outputId": "27327588-b979-4c75-ca07-01737cd4888c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.7001999999999999\n",
            "Average Precision: 0.7336\n",
            "Average F1-score: 0.8134\n",
            "Average AUC: 0.6334\n"
          ]
        }
      ]
    }
  ]
}