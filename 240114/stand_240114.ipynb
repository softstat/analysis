{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuPCVy7BuftUrjL987BgQ+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So9eFOLFEP4c",
        "outputId": "2e652c19-df94-42e6-f362-e72a87e2b454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CpMUNk_EX1i",
        "outputId": "bb62e4a7-553d-4a61-dc25-b493b7b8a9fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive"
      ],
      "metadata": {
        "id": "tV22sB9gEYzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4be75b-075d-4a09-c05d-8c809dc6c4a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfv4bZCEaEf",
        "outputId": "928f123d-dc96-4e3d-c291-0034889c863a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "non_PRC = pd.read_csv('stand/stand.csv')\n",
        "PRC = pd.read_csv('stand/stand_par.csv')\n",
        "clinical_assessment = pd.read_excel('Clinical Assessment.xlsx')"
      ],
      "metadata": {
        "id": "lSeKq_G5EbHF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import warnings\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y3d0mefjEjUT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = clinical_assessment.iloc[:,9]"
      ],
      "metadata": {
        "id": "FMdzcvvXEmLp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del score[0]\n",
        "del score[1]\n",
        "del score[2]\n",
        "del score[3]\n",
        "del score[7]\n",
        "del score[9]\n",
        "del score[10]\n",
        "del score[13]\n",
        "del score[15]\n",
        "del score[16]\n",
        "del score[17]\n",
        "del score[18]\n",
        "del score[19]\n",
        "del score[20]\n",
        "del score[21]\n",
        "del score[22]\n",
        "del score[23]\n",
        "del score[24]\n",
        "del score[25]\n",
        "del score[26]\n",
        "del score[27]\n",
        "del score[31]\n",
        "del score[34]\n",
        "del score[36]\n",
        "del score[39]\n",
        "del score[44]\n",
        "del score[45]\n"
      ],
      "metadata": {
        "id": "BgyCQsxyEoVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "for value in score:\n",
        "    if value >= 45:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK73bpUsEqMc",
        "outputId": "5ace4f7f-1b73-4747-ddc3-d87b5202be15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-paretic Side"
      ],
      "metadata": {
        "id": "R6saQXBUEtzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_non = pd.DataFrame(non_PRC)\n",
        "y = pd.DataFrame(y)\n",
        "non = pd.concat([y,df_non],axis=1)\n",
        "colname = list(non.columns)\n",
        "colname[0] = \"score\"\n",
        "non.columns = colname\n",
        "non.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1NwUrLXErpM",
        "outputId": "8a6771c2-1d38-46b0-8fdc-d8a63ab87049"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['score', 'Unnamed: 0', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
              "       'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16',\n",
              "       'PC17', 'PC18', 'PC19'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = non.loc[:,['PC2','PC10','PC15']]\n",
        "y = non['score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123, stratify=y)"
      ],
      "metadata": {
        "id": "LkGOvGZTEvfm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "z13gQSGCE0mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El6jdv5QExYm",
        "outputId": "c40027cd-32be-4fb3-e0f8-43e2904a5b44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.9285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "0wx96wXKE3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHb1549mE47B",
        "outputId": "85a2457b-f854-4a52-9745-051ed8591440"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.75\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.857\n",
            "Average AUC: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Linear"
      ],
      "metadata": {
        "id": "HKj2XQr1E69t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=2, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf_9r7aPE8me",
        "outputId": "8a4f5e1b-155b-4d48-c92a-91cbbcd4457e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.9285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM Poly"
      ],
      "metadata": {
        "id": "12jDiPduE-tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=2, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hRRw1dsFARi",
        "outputId": "23e0574a-db60-426d-bd34-a071901dfa2a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.75\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.857\n",
            "Average AUC: 0.8335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "VxtdgCiDFCUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8x8Y9q8FD2r",
        "outputId": "3b4fc0b7-51ea-45ef-b591-ca0a22df91c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.75\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.857\n",
            "Average AUC: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paretic-Side"
      ],
      "metadata": {
        "id": "uQNVk_1LFKXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_par = pd.DataFrame(PRC)\n",
        "y = pd.DataFrame(y)\n",
        "par = pd.concat([y,df_par],axis=1)\n",
        "colname = list(par.columns)\n",
        "colname[0] = \"score\""
      ],
      "metadata": {
        "id": "VDW4v6BlFIim"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "X = par.loc[:,['PC7']]\n",
        "y = par['score']\n",
        "X_train , X_test , y_train , y_test  = train_test_split(X,y,test_size = 0.4,random_state=123,stratify=y)"
      ],
      "metadata": {
        "id": "mo2TiT7XFNpK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### logistic regression"
      ],
      "metadata": {
        "id": "djXq0aT_FPZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "\n",
        "# 선택된 특성으로 모델 학습\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "accuracy_scores = cross_val_score(lr_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(lr_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(lr_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(lr_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_b1Zd9RFPtK",
        "outputId": "b95ab324-6ad7-4713-bb8f-f01976c1c255"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.9285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic RandomForest"
      ],
      "metadata": {
        "id": "rLK_r_D3FRnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 모델과 하이퍼파라미터 출력\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "accuracy_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_rf_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 5 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO-P30jvFTxb",
        "outputId": "452717dd-fb06-4bce-b434-838b8882e9db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.9285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Linear"
      ],
      "metadata": {
        "id": "HqpvJiFgFWBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear'],\n",
        "    'degree':[2,3,4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=2, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4va66LsEFXpo",
        "outputId": "3d7d8a04-1140-40e6-cc94-a4ae65edb9fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.875\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.9285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic SVM Poly"
      ],
      "metadata": {
        "id": "nzoKLK50FZ-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['poly'],\n",
        "    'degree': [2, 3, 4],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(SVC(random_state=123), param_grid, cv=2, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_svm_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K5jQ3mTFb6N",
        "outputId": "48577159-3f31-40b7-b259-a6382124a782"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.75\n",
            "Average Precision: 0.875\n",
            "Average F1-score: 0.8285\n",
            "Average AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### paretic XGBoost"
      ],
      "metadata": {
        "id": "8Erp4HXJFehN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 2],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=123), param_grid, cv=2, scoring='accuracy')\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "accuracy_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='accuracy', cv=2)\n",
        "precision_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='precision', cv=2)\n",
        "f1_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='f1', cv=2)\n",
        "auc_scores = cross_val_score(best_xgb_model, X_test, y_test, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Display the average performance metrics over the 2 folds\n",
        "print(\"Average Accuracy:\", np.mean(np.round(accuracy_scores,3)))\n",
        "print(\"Average Precision:\", np.mean(np.round(precision_scores,3)))\n",
        "print(\"Average F1-score:\", np.mean(np.round(f1_scores,3)))\n",
        "print(\"Average AUC:\", np.mean(np.round(auc_scores,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dklVCvhYFgO-",
        "outputId": "9c7cee68-7ac9-48b4-9fc6-bd5b0f01cf2d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.75\n",
            "Average Precision: 0.75\n",
            "Average F1-score: 0.857\n",
            "Average AUC: 0.5\n"
          ]
        }
      ]
    }
  ]
}